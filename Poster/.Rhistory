geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Tak")
best_model_full %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count = desc(count)) %>%
ungroup() %>%
ggplot(aes(reorder(value, -count), count))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Task")
ggsave("bestfit.png")
library(tidyverse)
library(kableExtra)
library(knitr)
library(magick)
rm(list=ls())
theme_set(theme_minimal())
#knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
discountingtasksnames <- c("speedup.small.present, speedup.small.future, speedup.large.future, speedup.large.present, td.small.present, td.large.present, td.small.future, td.large.future")
discountingtasksnames <- unlist(strsplit(discountingtasksnames, ","))
discountingtasksnames <- str_replace_all(discountingtasksnames, fixed(" "), "")
######
taskname <- discountingtasksnames
taskname <- sort(as.character(taskname))
taskname <- str_replace(taskname, "td", "Time Discounting")
taskname <- str_replace_all(taskname, fixed("."), " ")
proper=function(x) paste0(toupper(substr(x, 1, 1)), tolower(substring(x, 2)))
taskname <- proper(taskname)
abbreviation <- c("slf", "slp", "ssf", "ssp", "tdlf", "tdlp", "tdsf", "tdsp")
sooner <- c("1 month", "today")
later <- c("7 months", "6 months")
maximum.payment.size <- c("300", "300", "30", "30")
methods.table <- data.frame(taskname, abbreviation, sooner, later, maximum.payment.size)
z <- methods.table %>%
kable(align = 'r', col.names = c("Discounting Task", "Abbrev.", "Sooner Payment", "Later Payment", "Maximum Payment"), format = "latex")
kable_as_image(z, filename = "discount_tasks")
best_model_full %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count = desc(count)) %>%
ungroup() %>%
ggplot(aes(reorder(value, -count), count))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Task", title = "Models Which Fits the Most People")
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
library(broom)
library(glmnet)
library(MultivariateRandomForest)
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count <- as.numeric(respond.count)
female <- db$gender[which(db$gender==0)]
female <- sum(female == 0)
male <- db$gender[which(db$gender==1)]
male <- sum(male == 1)
## final sample size
final.samplesize <- nrow(db)
## age correlations
age.min <- min(db$age, na.rm = TRUE)
age.max <- max(db$age, na.rm = TRUE)
###########
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
pc <- PCA(db, graph = FALSE)
pc$var$cor
z <- pc$var
db <- db %>% mutate_all(as.numeric)
db[is.na(db)] <- -1
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_x <- as.matrix(train_x)
train_y = train %>% select(one_of(all.columns))
train_y <- as.matrix(train_y)
test_x <- test %>% select(-one_of(all.columns))
test_x <- as.matrix(test_x)
test_y <- test %>% select(one_of(all.columns))
test_y <- as.matrix(test_y)
results <- as.data.frame(all.columns) %>%
mutate(Discounting = as.character(all.columns),
rsq = 1:n(),
opt.lambda = 1:n()) %>%
select(-all.columns)
y = db$average.consistent
x <- db %>% select(-one_of(all.columns)) %>% data.matrix()
lambdas <- 10^seq(3, -2, by = -.1)
fit <- glmnet(x, y, alpha = 0, lambda = lambdas)
cv_fit <- cv.glmnet(x, y, alpha = 0, lambda = lambdas)
plot(cv_fit)
opt_lambda <- cv_fit$lambda.min
opt_lambda
fit <- cv_fit$glmnet.fit
z <- rbind(fit, fit)
zz <- fit
zz
y_predicted <- predict(z[[2]], s = opt_lambda, newx = x)
best_model_full %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count = desc(count)) %>%
ungroup() %>%
ggplot(aes(reorder(value, -count), count))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Task", title = "Models Which Fits the Most People")
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
library(broom)
library(glmnet)
library(MultivariateRandomForest)
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count <- as.numeric(respond.count)
female <- db$gender[which(db$gender==0)]
female <- sum(female == 0)
male <- db$gender[which(db$gender==1)]
male <- sum(male == 1)
## final sample size
final.samplesize <- nrow(db)
## age correlations
age.min <- min(db$age, na.rm = TRUE)
age.max <- max(db$age, na.rm = TRUE)
###########
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
pc <- PCA(db, graph = FALSE)
pc$var$cor
z <- pc$var
db <- db %>% mutate_all(as.numeric)
db[is.na(db)] <- -1
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_x <- as.matrix(train_x)
train_y = train %>% select(one_of(all.columns))
train_y <- as.matrix(train_y)
test_x <- test %>% select(-one_of(all.columns))
test_x <- as.matrix(test_x)
test_y <- test %>% select(one_of(all.columns))
test_y <- as.matrix(test_y)
results <- as.data.frame(all.columns) %>%
mutate(Discounting = as.character(all.columns),
rsq = 1:n(),
opt.lambda = 1:n()) %>%
select(-all.columns)
y = db$average.consistent
x <- db %>% select(-one_of(all.columns)) %>% data.matrix()
lambdas <- 10^seq(3, -2, by = -.1)
fit <- glmnet(x, y, alpha = 0, lambda = lambdas)
cv_fit <- cv.glmnet(x, y, alpha = 0, lambda = lambdas)
plot(cv_fit)
opt_lambda <- cv_fit$lambda.min
opt_lambda
fit <- cv_fit$glmnet.fit
y_predicted <- predict(fit, s = opt_lambda, newx = x)
# Sum of Squares Total and Error
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
# R squared
rsq <- 1 - sse / sst
rsq
best_model_full <- NA
for (i in 1:nrow(results)){
y = unlist(db[results[i,1]])
x <- db %>% select(-one_of(all.columns)) %>% data.matrix()
z <- x[1,]
lambdas <- 10^seq(3, -2, by = -.1)
fit <- glmnet(x, y, alpha = 0, lambda = lambdas)
summary(fit)
cv_fit <- cv.glmnet(x, y, alpha = 0, lambda = lambdas)
#plot(cv_fit)
opt_lambda <- cv_fit$lambda.min
results[i,3] <- opt_lambda # save
fit <- cv_fit$glmnet.fit
for (j in 1:nrow(db)){
x1 <- t(x[j,] %>% as.matrix())
y1 <- t(y[j] %>% as.matrix())
y_predicted <- predict(fit, s = opt_lambda, newx = x1)
# Sum of Squares Error
sse <- sum((y_predicted - y[j])^2)
# Save Results
results[i,3+j] <- sse
}
y_predicted <- predict(fit, s = opt_lambda, newx = x)
# Sum of Squares Total and Error
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
# R squared
rsq <- 1 - sse / sst
results[i,2] <- rsq
}
for (k in 1:nrow(db)){
best_model <- results[which.min(results[,3+k]),1]
best_model_full <- rbind(best_model_full, best_model)
}
best_model_full
best_model_full[-1,]
best_model_full <- best_model_full[-1,] %>% as_tibble()
for (j in 1:1){
x1 <- t(x[j,] %>% as.matrix())
y1 <- t(y[j,] %>% as.matrix())
y_predicted <- predict(fit, s = opt_lambda, newx = x1)
# Sum of Squares Error
sse <- sum((y_predicted - y[j])^2)
results[i,3+j] <- sse
}
best_model_full %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count = desc(count)) %>%
ungroup() %>%
ggplot(aes(reorder(value, -count), count))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Task", title = "Models Which Fits the Most People")
ggsave("bestfit.png")
best_model_full %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count = desc(count)) %>%
ungroup() %>%
ggplot(aes(reorder(value, -count), count))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Task", title = "Models Which Fits the Most People?")
ggsave("bestfit.png")
ggsave("bestfit.png", bg = "transparent")
results
View(results)
results %>% select(Discounting, rsq)
results %>%
select(Discounting, rsq) %>%
kable()
results %>%
select(Discounting, rsq) %>%
kable(format = "latex")
?kable
rsqmodels <- results %>%
select(Discounting, rsq) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq))
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
?kable_as_image
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = c("\usepackage{caption}", "\caption*{My great table}"))
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = c("\\usepackage{caption}", "\\caption*{My great table}"))
?kable
kable_as_image(rsqmodels, filename = "RSQ_table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
mtcars
mtcars %>%
kable(format = "latex", caption = "I'm a dummy table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
kable_as_image(z, filename = "dummy table")
dummy <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(dummy, filename = "dummy table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
library(broom)
library(glmnet)
library(MultivariateRandomForest)
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count <- as.numeric(respond.count)
female <- db$gender[which(db$gender==0)]
female <- sum(female == 0)
male <- db$gender[which(db$gender==1)]
male <- sum(male == 1)
## final sample size
final.samplesize <- nrow(db)
## age correlations
age.min <- min(db$age, na.rm = TRUE)
age.max <- max(db$age, na.rm = TRUE)
###########
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
pc <- PCA(db, graph = FALSE)
pc$var$cor
z <- pc$var
db <- db %>% mutate_all(as.numeric)
db[is.na(db)] <- -1
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_x <- as.matrix(train_x)
train_y = train %>% select(one_of(all.columns))
train_y <- as.matrix(train_y)
test_x <- test %>% select(-one_of(all.columns))
test_x <- as.matrix(test_x)
test_y <- test %>% select(one_of(all.columns))
test_y <- as.matrix(test_y)
results <- as.data.frame(all.columns) %>%
mutate(Discounting = as.character(all.columns),
rsq = 1:n(),
opt.lambda = 1:n()) %>%
select(-all.columns)
y = db$average.consistent
x <- db %>% select(-one_of(all.columns)) %>% data.matrix()
lambdas <- 10^seq(3, -2, by = -.1)
fit <- glmnet(x, y, alpha = 0, lambda = lambdas)
cv_fit <- cv.glmnet(x, y, alpha = 0, lambda = lambdas)
plot(cv_fit)
opt_lambda <- cv_fit$lambda.min
opt_lambda
fit <- cv_fit$glmnet.fit
y_predicted <- predict(fit, s = opt_lambda, newx = x)
# Sum of Squares Total and Error
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
# R squared
rsq <- 1 - sse / sst
rsq
best_model_full <- NA
for (i in 1:nrow(results)){
y = unlist(db[results[i,1]])
x <- db %>% select(-one_of(all.columns)) %>% data.matrix()
z <- x[1,]
lambdas <- 10^seq(3, -2, by = -.1)
fit <- glmnet(x, y, alpha = 0, lambda = lambdas)
summary(fit)
cv_fit <- cv.glmnet(x, y, alpha = 0, lambda = lambdas)
#plot(cv_fit)
opt_lambda <- cv_fit$lambda.min
results[i,3] <- opt_lambda # save
fit <- cv_fit$glmnet.fit
for (j in 1:nrow(db)){
x1 <- t(x[j,] %>% as.matrix())
y1 <- t(y[j] %>% as.matrix())
y_predicted <- predict(fit, s = opt_lambda, newx = x1)
# Sum of Squares Error
sse <- sum((y_predicted - y[j])^2)
# Save Results
results[i,3+j] <- sse
}
y_predicted <- predict(fit, s = opt_lambda, newx = x)
# Sum of Squares Total and Error
sst <- sum((y - mean(y))^2)
sse <- sum((y_predicted - y)^2)
# R squared
rsq <- 1 - sse / sst
results[i,2] <- rsq
}
for (k in 1:nrow(db)){
best_model <- results[which.min(results[,3+k]),1]
best_model_full <- rbind(best_model_full, best_model)
}
best_model_full <- best_model_full[-1,] %>% as_tibble()
best_model_full %>%
group_by(value) %>%
summarise(count = n()) %>%
arrange(count = desc(count)) %>%
ungroup() %>%
ggplot(aes(reorder(value, -count), count))+
geom_bar(stat = "identity")+
theme(axis.text.x = element_text(angle = 90, hjust = 1))+
labs(x = "Discounting Task", title = "Models Which Fits the Most People?")
ggsave("bestfit.png", bg = "transparent")
dummy <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(dummy, filename = "dummy table", bookta)
dummy <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(dummy, filename = "dummy table")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
kable_as_image(rsqmodels, filename = "RSQ_table")
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = "\captionsetup[table]{labelformat=empty}")
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = "\\captionsetup[table]{labelformat=empty}")
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = NULL)
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = NULL)
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex", caption = "R Squared Values by Discount Method") %>%
kable(format = "latex", caption = "R Squared Values by Discount Method")
rsqmodels <- results %>%
select(Discounting, rsq) %>%
arrange(desc(rsq)) %>%
kable(format = "latex")
kable_as_image(rsqmodels, filename = "RSQ_table", latex_header_includes = NULL)
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count
View(db)
map(db, from=c("comparison.shop"), to=c("zz")))
map(db, from=c("comparison.shop"), to=c("zz"))
map(db, (from=c("comparison.shop"), to=c("zz")))
mapapply(db, (from=c("comparison.shop"), to=c("zz")))
mapapply(db, from=c("comparison.shop"), to=c("zz"))
mapply(db, from=c("comparison.shop"), to=c("zz"))
mapply(db, from="comparison.shop", to=c"zz")
setnames(db, from="comparison.shop", to=c"zz")
setnames(db, from="comparison.shop", to="zz")
library(data.table)
setnames(db, from="comparison.shop", to="zz")
setnames(db, from="comparison.shop", to="zz")
setnames(db, old ="comparison.shop", new ="zz")
View(db)
