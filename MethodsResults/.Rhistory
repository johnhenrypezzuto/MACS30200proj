variation <- as_tibble(apply(db, 2, var))
variation <- add_rownames(variation, "Column.Name")
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name) %>%
unlist(novar[,1], use.names = FALSE)
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name) %>%
unlist(novar[,1], use.names = FALSE)
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name) %>%
unlist(novar[,1], use.names = FALSE)
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name)
novar %>% unlist(novar[,1], use.names = FALSE)
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name)
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name)
View(novar)
variation <- as_tibble(apply(db, 2, var))
variation <- add_rownames(variation, "Column.Name")
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name)
novar %>% unlist(novar[,1], use.names = FALSE)
novar <- novar %>% unlist(novar[,1], use.names = FALSE)
db <- db %>% select(-one_of(novar))
prcomp(na.omit(db), scale. = TRUE)
prcomp(na.omit(db))
prcomp(na.omit(db), scale=TRUE)
prcomp(na.omit(db))
pc <- prcomp(na.omit(db))
View(pc)
summary(pc)
pc <- prcomp(na.omit(db))
summary(pc)
biplot(pc)
library(tidyverse)
library(knitr)
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
variation <- as_tibble(apply(db, 2, var))
variation <- add_rownames(variation, "Column.Name")
novar <- variation %>%
mutate_each(funs(round(.,2)), -Column.Name) %>%
filter(value == 0) %>%
select(Column.Name)
novar <- novar %>% unlist(novar[,1], use.names = FALSE)
db <- db %>% select(-one_of(novar))
pc <- prcomp(na.omit(db), scale=TRUE)
db$Military
db$Confused
db <- db %>% select(-one_of(novar), -Confused)
pc <- prcomp(na.omit(db), scale=TRUE)
pc <- prcomp(na.omit(db), scale=TRUE)
library(FactoMineR)
pca(db)
PCA(db)
pc <- prcomp(na.omit(db), scale=TRUE)
pc <- prcomp(na.omit(db)
pc
pc <- prcomp(na.omit(db)
pc
pc <- prcomp(na.omit(db))
pc
summary(pc)
PCA(db)
PCA(db)$var
pc2 <- PCA(db)
pc2$ind
pc2$call
?PCA
pc2$eig
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count <- as.numeric(respond.count)
female <- db$gender[which(db$gender==0)]
female <- sum(female == 0)
male <- db$gender[which(db$gender==1)]
male <- sum(male == 1)
## final sample size
final.samplesize <- nrow(db)
## age correlations
age.min <- min(db$age, na.rm = TRUE)
age.max <- max(db$age, na.rm = TRUE)
discountingtasksnames <- c("speedup.small.present, speedup.small.future, speedup.large.future, speedup.large.present, td.small.present, td.large.present, td.small.future, td.large.future")
discountingtasksnames <- unlist(strsplit(discountingtasksnames, ","))
discountingtasksnames <- str_replace_all(discountingtasksnames, fixed(" "), "")
taskname <- discountingtasksnames
taskname <- sort(as.character(taskname))
taskname <- str_replace(taskname, "td", "Time Discounting")
taskname <- str_replace_all(taskname, fixed("."), " ")
proper=function(x) paste0(toupper(substr(x, 1, 1)), tolower(substring(x, 2)))
taskname <- proper(taskname)
abbreviation <- c("slf", "slp", "ssf", "ssp", "tdlf", "tdlp", "tdsf", "tdsp")
sooner <- c("1 month", "today")
later <- c("7 months", "6 months")
maximum.payment.size <- c("300", "300", "30", "30")
methods.table <- data.frame(taskname, abbreviation, sooner, later, maximum.payment.size)
methods.table %>% kable(align = 'r', col.names = c("Discounting Task","Abbreviation" , "Sooner Payment", "Later Payment", "Maximum Payment Size"))
# variation <- as_tibble(apply(db, 2, var))
# variation <- add_rownames(variation, "Column.Name")
#
# novar <- variation %>%
#   mutate_each(funs(round(.,2)), -Column.Name) %>%
#   filter(value == 0) %>%
#   select(Column.Name)
#
# novar <- novar %>% unlist(novar[,1], use.names = FALSE)
#
# db <- db %>% select(-one_of(novar), -Confused)
db$Confused
pc <- prcomp(na.omit(db))
summary(pc)
pc2 <- PCA(db)
pc2$eig
pc2$eig
pc2 <- PCA(db)
pc2 <- PCA(db)
pc2 <- PCA(db, graph = FALSE)
pc2 <- PCA(na.omit(db), graph = FALSE)
pc2$eig
na.omit(db)
z <- na.omit(db)
View(z)
pc2 <- PCA(db, graph = FALSE)
install.packages("missMDA")
library(missMDA)
?imputePCA()
pc2 <- PCA(db, graph = FALSE)
pc2$eig
pc$eig
pc2$eig
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
install.packages("MultivariateRandomForest")
library(MultivariateRandomForest)
factor.cols = delay.discounting %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = colnames(beta.delta.results)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
library(MultivariateRandomForest)
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x = train %>% select(-all.columns)
train_x <- train %>% select(-all.columns)
View(train)
discountingtasksnames <- c("speedup.small.present, speedup.small.future, speedup.large.future, speedup.large.present, td.small.present, td.large.present, td.small.future, td.large.future")
discountingtasksnames <- unlist(strsplit(discountingtasksnames, ","))
discountingtasksnames <- str_replace_all(discountingtasksnames, fixed(" "), "")
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-all.columns)
train_x <- train %>% select(-factor.cols)
train_x <- train %>% select(factor.cols)
train_x <- train %>% select(patience.cols)
train_x <- train %>% select(hyperbolic_exponential.cols)
train_x <- train %>% select(beta.delta.cols)
train_x <- train %>% select(all.columns)
train_x <- train %>% select(-all.columns)
train_x <- train %>% select(-(all.columns))
train_x <- train %>% select(-c(all.columns))
train_x <- train %>% select(-all.columns)
train_x <- train %>% select(-all.columns)
train_x <- train %>% select(-all.columns)
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-all.columns)
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
train_x <- train %>% select(all.columns)
test_x <- test %>% select(-all.columns)
train_y = train %>% select(all.columns)
train_x <- train %>% select(-all.columns)
train_x <- train %>% select(-c(all.columns))
train_x <- train %>% select(c(all.columns))
train_x <- train %>% select(c(all.columns))
train_x <- train %>% select(c(all.columns))
train_y = train %>% select(-all.columns)
all.columns <- enquo(all.columns)
train_x <- train %>% select(c(all.columns))
train_x <- train %>% select(all.columns)
train_x <- train %>% select(!!all.columns)
train_y = train %>% select(-!!all.columns)
train_x <- train %>% select(!!all.columns)
train_y = train %>% select(-!!all.columns)
test_x <- test %>% select(-all.columns)
test_x <- test %>% select(all.columns)
test_x <- test %>% select(!!all.columns)
test_y <- test %>% select(!!all.columns)
test_y <- test %>% select(!!-all.columns)
test_y <- test %>% select(-!!all.columns)
train_x <- train %>% select(!!!all.columns)
train_y = train %>% select(!!!all.columns)
View(train_y)
train_x <- train %>% select(!!all.columns)
View(train_x)
train_y = train %>% select(!!all.columns)
train_y = train %>% select(-!!all.columns)
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
train_x <- train %>% select(all.columns)
train_y = train %>% select(-!!all.columns)
train_y = train %>% select(all.columns)
train_y = train %>% select(-all.columns)
train_y = train %>% select(-(all.columns))
train_y = train %>% select(-c(all.columns))
train_y = train %>% select(- c(all.columns))
train_y = train %>% select(-all.columns)
train_y = train %>% select(-one_of(all.columns))
test_y <- test %>% select(one_of(all.columns))
View(test_y)
View(test_x)
train_x <- train %>% select(all.columns)
train_y = train %>% select(-one_of(all.columns))
test_x <- test %>% select(all.columns)
test_y <- test %>% select(-one_of(all.columns))
View(test_y)
train_x <- train %>% select(-one_of(all.columns))
train_y = train %>% select(one_of(all.columns))
train_x <- train %>% select(-one_of(all.columns))
train_x <- train %>% select(-one_of(all.columns))
train_y = train %>% select(one_of(all.columns))
test_x <- test %>% select(-one_of(all.columns))
test_y <- test %>% select(one_of(all.columns))
?build_forest_predict(trainX, trainY, n_tree, m_feature, min_leaf, testX)
?build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count <- as.numeric(respond.count)
female <- db$gender[which(db$gender==0)]
female <- sum(female == 0)
male <- db$gender[which(db$gender==1)]
male <- sum(male == 1)
## final sample size
final.samplesize <- nrow(db)
## age correlations
age.min <- min(db$age, na.rm = TRUE)
age.max <- max(db$age, na.rm = TRUE)
discountingtasksnames <- c("speedup.small.present, speedup.small.future, speedup.large.future, speedup.large.present, td.small.present, td.large.present, td.small.future, td.large.future")
discountingtasksnames <- unlist(strsplit(discountingtasksnames, ","))
discountingtasksnames <- str_replace_all(discountingtasksnames, fixed(" "), "")
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_y = train %>% select(one_of(all.columns))
test_x <- test %>% select(-one_of(all.columns))
test_y <- test %>% select(one_of(all.columns))
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
View(test_x)
na.omit(db)
#library(MultivariateRandomForest)
build_forest_predict(na.omit(train_x), train_y, 100, 5, 5, test_x)
#library(MultivariateRandomForest)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
#library(MultivariateRandomForest)
db %>% select(contains(NA))
#library(MultivariateRandomForest)
db %>% select(contains("NA"))
```{r}
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
db[is.na(db)] <- -100
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_y = train %>% select(one_of(all.columns))
test_x <- test %>% select(-one_of(all.columns))
test_y <- test %>% select(one_of(all.columns))
taskname <- discountingtasksnames
taskname <- sort(as.character(taskname))
taskname <- str_replace(taskname, "td", "Time Discounting")
taskname <- str_replace_all(taskname, fixed("."), " ")
proper=function(x) paste0(toupper(substr(x, 1, 1)), tolower(substring(x, 2)))
taskname <- proper(taskname)
abbreviation <- c("slf", "slp", "ssf", "ssp", "tdlf", "tdlp", "tdsf", "tdsp")
sooner <- c("1 month", "today")
later <- c("7 months", "6 months")
maximum.payment.size <- c("300", "300", "30", "30")
methods.table <- data.frame(taskname, abbreviation, sooner, later, maximum.payment.size)
methods.table %>% kable(align = 'r', col.names = c("Discounting Task","Abbreviation" , "Sooner Payment", "Later Payment", "Maximum Payment Size"))
#library(MultivariateRandomForest)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
#library(MultivariateRandomForest)
db
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
#library(MultivariateRandomForest)
as.numeric(db)
#library(MultivariateRandomForest)
db %>% mutate_all(as.numeric)
#library(MultivariateRandomForest)
db <- db %>% mutate_all(as.numeric)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
db[is.na(db)] <- -100
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_y = train %>% select(one_of(all.columns))
test_x <- test %>% select(-one_of(all.columns))
test_y <- test %>% select(one_of(all.columns))
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
as.matrix(db)
db <- as.matrix(db)
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_y = train %>% select(one_of(all.columns))
train_x <- as.matrix(train_x)
rm(list = ls())
library(tidyverse)
library(knitr)
library(kableExtra)
library(FactoMineR)
theme_set(theme_minimal())
knitr::opts_chunk$set(include = FALSE, echo=FALSE, warning=FALSE, message=FALSE)
db <- read_csv("full_calculations.csv") %>%
select(-IPAddress, -X1,-(nostalgic:F_disgust)) %>%
mutate_all(as.numeric)
survey.data <- read_csv("Delay Discounting_human_80.csv")
respond.count <- survey.data %>%
select(Status) %>%
filter(!Status == "Survey Preview") %>%
count()
respond.count <- as.numeric(respond.count)
female <- db$gender[which(db$gender==0)]
female <- sum(female == 0)
male <- db$gender[which(db$gender==1)]
male <- sum(male == 1)
## final sample size
final.samplesize <- nrow(db)
## age correlations
age.min <- min(db$age, na.rm = TRUE)
age.max <- max(db$age, na.rm = TRUE)
discountingtasksnames <- c("speedup.small.present, speedup.small.future, speedup.large.future, speedup.large.present, td.small.present, td.large.present, td.small.future, td.large.future")
discountingtasksnames <- unlist(strsplit(discountingtasksnames, ","))
discountingtasksnames <- str_replace_all(discountingtasksnames, fixed(" "), "")
###########
factor.cols = db %>% select(ends_with("indifference.consistent"), average, average.consistent) %>% colnames(.)
patience.cols = c("Patience", "s.Patience", "td.Patience")
hyperbolic_exponential.cols = db %>%
select(ends_with(".k"), ends_with("exponential")) %>%
colnames(.)
beta.delta.cols = db %>%
select(ends_with(".beta"), ends_with(".delta")) %>%
colnames(.)
all.columns <- c(factor.cols, patience.cols, hyperbolic_exponential.cols, beta.delta.cols)
set.seed(8675309)
smp_size <- floor(0.70 * nrow(db))
train_ind <- sample(seq_len(nrow(db)), size = smp_size)
db[is.na(db)] <- -100
train <- db[train_ind, ]
test <- db[-train_ind, ]
train_x <- train %>% select(-one_of(all.columns))
train_x <- as.matrix(train_x)
train_y = train %>% select(one_of(all.columns))
train_y <- as.matrix(train_y)
test_x <- test %>% select(-one_of(all.columns))
test_x <- as.matrix(test_x)
test_y <- test %>% select(one_of(all.columns))
test_y <- as.matrix(test_y)
taskname <- discountingtasksnames
taskname <- sort(as.character(taskname))
taskname <- str_replace(taskname, "td", "Time Discounting")
taskname <- str_replace_all(taskname, fixed("."), " ")
proper=function(x) paste0(toupper(substr(x, 1, 1)), tolower(substring(x, 2)))
taskname <- proper(taskname)
abbreviation <- c("slf", "slp", "ssf", "ssp", "tdlf", "tdlp", "tdsf", "tdsp")
sooner <- c("1 month", "today")
later <- c("7 months", "6 months")
maximum.payment.size <- c("300", "300", "30", "30")
methods.table <- data.frame(taskname, abbreviation, sooner, later, maximum.payment.size)
methods.table %>% kable(align = 'r', col.names = c("Discounting Task","Abbreviation" , "Sooner Payment", "Later Payment", "Maximum Payment Size"))
#library(MultivariateRandomForest)
db <- db %>% mutate_all(as.numeric)
build_forest_predict(train_x, train_y, 100, 5, 5, test_x)
PCA(db)
pc <- PCA(db)
pc <- PCA(db, graph = FALSE)
pc$eig
z <- pc$eig
View(z)
pc <- PCA(db, graph = FALSE)
View(pc)
install.packages("dummies")
pc$eig
pc$var
z <- pc$var
View(z)
pc <- PCA(db, graph = FALSE)
z <- pc$var
pc$var$contrib
pc$var$cor
